{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcda489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import re\n",
    "from pprint import pformat\n",
    "from json import dumps,loads\n",
    "from kafka import KafkaConsumer, KafkaProducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beea9bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC_Step1_NAME=\"Sahamyab-Session_16\"\n",
    "TOPIC_Step2_NAME=\"Sahamyab-Session_16_2\"\n",
    "KAFKA_SERVER=\"kafka-broker:29092\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6df3e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags(text):\n",
    "    tags = re.findall(r\"#(\\w+)\", text)\n",
    "    #  r\"#(\\w+)\" matches all occurrences of a hashtag followed by one or more word characters\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53afe209",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = KafkaConsumer(\n",
    "     TOPIC_Step1_NAME, #This is the name of the Kafka topic from which the consumer will read data.\n",
    "     bootstrap_servers=[KAFKA_SERVER],\n",
    "     auto_offset_reset='earliest',\n",
    "     enable_auto_commit=True,\n",
    "     group_id='hashtag-group',\n",
    "     value_deserializer=lambda x: loads(x.decode('utf-8')),\n",
    "     key_deserializer=lambda x : str(x),\n",
    "     client_id='consumer-of-tweets'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e63fbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  key_deserializer=lambda x : str(x), This function is called to deserialize the key of each message. Here, itâ€™s converting each key to a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeaad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(bootstrap_servers=['kafka-broker:29092'], value_serializer=lambda x: dumps(x).encode('utf-8'),\n",
    "                        key_serializer=str.encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9fbb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell processes messages from a Kafka consumer\n",
    "cnt=1\n",
    "for message in consumer:\n",
    "    try : \n",
    "        data=message.value\n",
    "        del data['raw-data']\n",
    "        print(\"-=-\"*20)\n",
    "        print(f\"#{cnt:4} - Processing Tweet ID {message.key}\")\n",
    "        tags=get_tags(data['content'])\n",
    "        print(f\"Tags : {tags}\")\n",
    "        data[\"hashtags\"] = tags\n",
    "        producer.send(TOPIC_Step2_NAME, value=data, key= data['id'])\n",
    "        cnt+=1\n",
    "    except Exception as ex:\n",
    "        print(\"%%%-\"*20)\n",
    "        print(ex)\n",
    "        \n",
    "\"\"\"        \n",
    "This code reads messages from a Kafka consumer, extracts hashtags from the message content,\n",
    "updates the message data with the extracted hashtags, and sends the updated data to a Kafka\n",
    "producer for further processing!        \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa9e4c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
